<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Jiaye Teng 滕佳烨</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-104083228-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<link rel="stylesheet" type="text/css" href="./css/siminar-home.css">
<tr valign="top">
<td id="layout-menu">
<img src="../pic/FAI-WB.png" width=100>
<div class="menu-item"><a href="../index.html">FAI-Seminar</a></div>
<div class="menu-item"><a href="./logistic.html">基础信息</a></div>
<div class="menu-item"><a href="./previous.html">往期讲座</a></div>
<div class="menu-item"><a href="./audience.html">观众须知</a></div>
<div class="menu-item"><a href="./speaker.html">讲者须知</a></div>
<div class="menu-item"><a href="./enrollment.html">讲者报名</a></div>
<div class="menu-item"><a href="./contact.html">联系我们</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>FAI-Seminar: Previous Talks</h1></div>



<br> 2024 R02 </br>
<table>
<tr>
  <td style="width: 10%;">Time</td>
  <td style="width: 15%;">Speaker</td>
  <td style="width: 60%;">Talk Title</td>
  <td style="width: 5%;">Talk Info</td>
  <td style="width: 5%;">Paper</td>
  <td style="width: 5%;">Video</td>
</tr>
<tr>
  <td>07/19</td>
  <td><a href="https://zbh2047.github.io/">张博航</a><br>(北京大学)</td>
  <td>Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness</td>
  <td><a href="https://mp.weixin.qq.com/s/Pih8KXORGTTWsbvVsAxR4Q">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/1810.00826">1</a>], [<a href="https://arxiv.org/abs/2301.09505">2</a>], <br>[<a href="https://arxiv.org/abs/2302.07090">3</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1WCp1eDEWU">B站</a></td>
</tr>
<tr>
  <td>08/09</td>
  <td><a href="https://lithiumda.github.io/">黎善达</a><br>(CMU)</td>
  <td>Inference Scaling Law of Large Language Models and Second-Prize Winning Solution of AIMO</td>
  <td><a href="https://mp.weixin.qq.com/s/6ed1LNQR1AudvpwjKkKe5A">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2408.00724">1</a>], [<a href="https://blog.ml.cmu.edu/2024/07/29/cmu-math-teams-innovative-approach-secures-2nd-place-at-the-aimo-prize/">2</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1snsVePEBL">B站</a></td>
</tr>
<tr>
  <td>08/16</td>
  <td><a href="https://tianhaowang.ttic.edu/">王天浩</a><br>(TTIC)</td>
  <td>Tractable training dynamics of transformers for in-context learning</td>
  <td><a href="https://mp.weixin.qq.com/s/AYNLP-gnIUeju9jxxmmsTg">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/pdf/2402.19442">1</a>], [<a href="">2</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1ahpPemEfW">B站</a></td>
</tr>
<tr>
  <td>08/23</td>
  <td><a href="https://uuujf.github.io/">吴京风</a><br>(Berkeley)</td>
  <td>Reimaging Gradient Descent: Large Stepsize, Oscillation, and Acceleration</td>
  <td><a href="https://mp.weixin.qq.com/s/7RDbinxKeHooyeZkpPaJsg">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2402.15926">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV15Vxje8Ei7/">B站</a></td>
</tr>
<tr>
  <td>08/30</td>
  <td><a href="https://gavenma.github.io/">马梓业</a><br>(港城大)</td>
  <td>Navigating the non-convex landscape via amplifying escape directions of saddle points</td>
  <td><a href="https://mp.weixin.qq.com/s/A3YV7EuzsN1BaiJ0xa-z3A">Talk Info</a></td>
  <td>[<a href="https://proceedings.mlr.press/v202/ma23f.html">1</a>], [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/7db2348b5bfeca620aa7327df815adcc-Paper-Conference.pdf">2</a>], <br>[<a href="https://proceedings.mlr.press/v238/ma24a/ma24a.pdf">3</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1XWxXetEFd/">B站</a></td>
</tr>
<tr>
  <td>11/01</td>
  <td><a href="https://liuyonggsai.github.io/">刘勇</a><br>(中国人民大学)</td>
  <td>Can Retrieval Augmented Generation (RAG) Enhance the LLM’s Reasoning Capabilities?</td>
  <td><a href="https://mp.weixin.qq.com/s/smpyJCTeC3LfJQ4jAM6vRw">Talk Info</a></td>
  <td></td>
  <td><a href="https://www.bilibili.com/video/BV1jTDNY3EFR/">B站</a></td>
</tr>

</table>

<br> 2024 R01 </br>
<table>
<tr>
  <td>Time</td>
  <td>Speaker</td>
  <td>Talk Title</td>
  <td>Talk Info</td>
  <td>Paper</td>
  <td>Video</td>
</tr>
<tr>
  <td>Special talk 05/31</td>
  <td><a href="https://people.iiis.tsinghua.edu.cn/~jianli/">李建</a><br>(清华大学)</td>
  <td>Generalization Error and Implicit Bias of Gradient Methods in Deep Learning</td>
  <td><a href="https://mp.weixin.qq.com/s/WKWrtzx1Vvc8IGHXSMS4OA">Talk Info</a></td>
  <td></td>
  <td><a href="https://www.bilibili.com/video/BV1Jy411b7gc">B站</a></td>
</tr>
<tr>
  <td>03/08</td>
  <td><a href="https://www.runtianzhai.com/">翟润天</a><br>(CMU)</td>
  <td>On the Generalization of Representation Learning and Big Foundation Models</td>
  <td><a href="https://mp.weixin.qq.com/s/ai30Xt7drnTxDwhhXqI3vQ">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2306.00788">1</a>, <a href="https://arxiv.org/abs/2402.00645">2</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1sZ421t7mY">B站</a></td>
</tr>
<tr>
  <td>03/15</td>
  <td><a href="https://lsj2408.github.io/">罗胜杰</a><br>(北京大学)</td>
  <td>Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products</td>
  <td><a href="https://mp.weixin.qq.com/s/5OOx2b8CfgNV55uD7pWq1w">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2401.10216">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1sA4m1A7Cm">B站</a></td>
</tr>

<tr>
  <td>03/22</td>
  <td><a href="https://gaotianyu.xyz/about/">高天宇</a>(Princeton)</td>
  <td>Long-Context Language Modeling with Parallel Context Encoding</td>
  <td><a href="https://mp.weixin.qq.com/s/AZLO4vGfPxOuXjtA-CWqkg">Talk Info</a></td>
  <td></td>
  <td><a href="https://www.bilibili.com/video/BV1Cz421o7qr">B站</a></td>
</tr>

<tr>
  <td>03/29</td>
  <td><a href="https://difanzou.github.io/">邹荻凡</a><br>(香港大学)</td>
  <td>Faster Sampling without Isoperimetry via Diffusion-based Monte Carlo</td>
  <td><a href="https://mp.weixin.qq.com/s/LdstKx0K1aRGGOxcHkG36A">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2401.06325">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1DM4m1X7SA">B站</a></td>
</tr>
<tr>
  <td>04/05</td>
  <td> <a href="https://2prime.github.io/">陆一平</a><br>(NYU)</td>
  <td>Simulation-Calibrated Scientific Machine Learning</td>
  <td><a href="https://mp.weixin.qq.com/s/MSuv2uYUzO5gwIW8JinbzA">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2305.16527">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV19E421u73Q">B站</a></td>
</tr>

<tr>
  <td>04/12</td>
  <td><a href="https://dingliyu.net/">俞鼎力</a>(Princeton)</td>
  <td>Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks</td>
  <td><a href="https://mp.weixin.qq.com/s/eIdXRN9-fwHNaMWPyim5KA">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2310.02244">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1Fw4m127pn">B站</a></td>
</tr>
<tr>
  <td>04/19</td>
  <td> <a href="https://kaifeng.ac/">吕凯风</a>(Princeton)</td>
  <td>Understanding the Limitations of Neural Networks on Algorithmic Reasoning</td>
  <td><a href="https://mp.weixin.qq.com/s/VIOGFXiVyi2TYv6rK3S7Aw">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2311.18817">1</a>, <a href="https://arxiv.org/abs/2402.18510">2</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1Gz42167i8">B站</a></td>
</tr>
<tr>
  <td>04/26</td>
  <td><a href="https://www.cs.cmu.edu/~yuchenl4/">李禹辰</a><br>(CMU)</td>
  <td>Towards Mathematical Understanding of Modern Language Models</td>
  <td><a href="https://mp.weixin.qq.com/s/TkkciPkvzIloZ7joSwabcg">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2106.01580">1</a>, <a href="https://arxiv.org/abs/2303.04245">2</a>, <br><a href="https://arxiv.org/abs/2312.01429">3</a>, <a href=" ">4</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1F1421R7kb">B站</a></td>
</tr>



</table>


<br> 2023 R03 </br>
<table>
<tr>
  <td>Time</td>
  <td>Speaker</td>
  <td>Talk Title</td>
  <td>Talk Info</td>
  <td>Paper</td>
  <td>Video</td>
</tr>
<tr>
  <td>Special Talk 2/16</td>
  <td><a href="https://weihu.me/">胡威</a><br>(UMich)</td>
  <td>Hidden Structures in Neural Network Representations</td>
  <td><a href="https://mp.weixin.qq.com/s/CqgUz3FjimMqN_5E3lBAVw">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2306.17105">1</a>, <a href="https://arxiv.org/abs/2307.08286">2</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1qt421t7nY">B站</a></td>
</tr>
<tr>
  <td>11/10</td>
  <td><a href="https://truenobility303.github.io/">陈乐偲</a><br>(清华大学)</td>
  <td>Near-Optimal Nonconvex-Strongly-Convex Bilevel Optimization with Fully First-Order Oracles</td>
  <td><a href="https://mp.weixin.qq.com/s/lmiqKvzaoYzT3SXupWKD3Q">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2306.14853">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1Nu4y1h7kL">B站</a></td>
</tr>
<tr>
  <td>11/17</td>
  <td><a href="https://zbh2047.github.io/">张博航</a><br>(北京大学)</td>
  <td>Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective</td>
  <td><a href="https://mp.weixin.qq.com/s/e4-OUD3Cu3fzOeTxx6McgQ">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2305.15408">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1c34y1w7ZW">B站</a></td>
</tr>
<tr>
  <td>11/24</td>
  <td><a href="https://scholar.google.com/citations?user=6iYQL8MAAAAJ&hl=zh-CN&oi=ao">顾欣然</a><br>(清华大学)</td>
  <td>A Quadratic Synchronization Rule for Distributed Deep Learning</td>
  <td><a href="https://mp.weixin.qq.com/s/_4-MW0LxLi3vjQ_nYfCJng">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2310.14423">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1n64y177FA">B站</a></td>
</tr>
<tr>
  <td>12/1</td>
  <td><a href="http://jiaxins.io/">石佳欣</a>(DeepMind)</td>
  <td>MultiresConv: From Wavelet Theory to Long Context Modeling with Neural Networks</td>
  <td><a href="https://mp.weixin.qq.com/s/A53yqF_oo--gzgRin0B8rA">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2305.01638">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1hN4y1e7Dy">B站</a></td>
</tr>
<tr>
  <td>12/8</td>
  <td><a href="https://fengleifan.github.io/Feng-Lei.Fan.github.io/about.html">范凤磊</a><br>(香港中文<br>大学)</td>
  <td>In Pursuit of Deciphering ReLU Networks and Beyond</td>
  <td><a href="https://mp.weixin.qq.com/s/AoavRQYFJioqZ9JAgZYwqw">Talk Info</a></td>
  <td>[<a href="https://www.jmlr.org/papers/volume24/21-0579/21-0579.pdf">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1q64y1H7ii">B站</a></td>
</tr>
<tr>
  <td>12/15</td>
  <td>NeurIPS break</td>
</tr>
<tr>
  <td>12/22</td>
  <td><a href="https://clarabing.github.io/">刘冰彬</a><br>(CMU)</td>
  <td>Thinking Fast with Transformers: algorithmic reasoning with shortcuts</td>
  <td><a href="https://mp.weixin.qq.com/s/XMRJuhsC8AAO2EYQQBp5qw">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2210.10749">1</a>] (ICLR 23' oral), [<a href="https://arxiv.org/abs/2306.00946">2</a>] (NeurIPS 23' spotlight)</td>
  <td><a href="https://www.bilibili.com/video/BV1Se411z7HG">B站</a></td>
</tr>
<tr>
  <td>12/29</td>
  <td><a href="https://whenwen.github.io/">温凯越</a><br>(清华大学)</td>
  <td>Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars</td>
  <td><a href="https://mp.weixin.qq.com/s/UE0ZNEjed9VjenOdpWQNkg">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2312.01429">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1NK4y1r7jp">B站</a></td>
</tr>
<tr>
  <td>1/12</td>
  <td><a href="https://youkaichao.github.io/about">游凯超</a><br>(清华大学)</td>
  <td>Understand, Learn, and Adopt the PyTorch compiler (torch.compile)</td>
  <td><a href="https://mp.weixin.qq.com/s/xC-5RRu2zZgxdjSvHgz2ig">Talk Info</a></td>
  <td>[<a href="https://arxiv.org/abs/2305.11624">1</a>, <a href="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/fx_passes/efficient_conv_bn_eval.py">2</a>, <a href="https://github.com/thuml/depyf">3</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV14T4y187bN">B站</a></td>
</tr>
</table>

<br> 2023 R02 </br>
<table>
<tr>
  <td>Time</td>
  <td>Speaker</td>
  <td>Talk Title</td>
  <td>Paper</td>
  <td>Video</td>
</tr>
<tr>
  <td>(Special)09/15</td>
  <td><a href="https://ai.stanford.edu/~zhiyuanli/">李志远</a><br>(Stanford)</td>
  <td>The Generalization Benefit of Flatnes Regularization</td>
  <td>[<a href="https://arxiv.org/abs/2306.13239">1</a>][<a href="https://arxiv.org/abs/2307.11007">2</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1SN411n7TY/?spm_id_from=333.337.search-card.all.click">B站</a></td>
</tr>
<tr>
  <td>06/23</td>
  <td><a href="https://zbh2047.github.io/">张博航</a><br>(北京大学)</td>
  <td>Understanding the Expressivity of Subgraph-based GNNs for Graph Learning</td>
  <td>[<a href="https://arxiv.org/abs/2302.07090">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1gk4y1u722/?spm_id_from=333.999.0.0">B站</a></td>
</tr>
<tr>
  <td>06/30</td>
  <td><a href="https://lsj2408.github.io/">罗胜杰</a><br>(北京大学)</td>
  <td>One Transformer Can Understand Both 2D & 3D Molecular Data</td>
  <td>[<a href="https://openreview.net/forum?id=vZTp1oPV3PC">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV12m4y1a7G1/?spm_id_from=333.999.0.0">B站</a></td>
</tr>
<tr>
  <td>07/07</td>
  <td><a href="https://kindxiaoming.github.io/">刘子鸣</a><br>(MIT)</td>
  <td>Intelligence from hunger</td>
  <td>[<a href="https://arxiv.org/abs/2210.01117">1</a>], [<a href="https://arxiv.org/abs/2305.08746">2</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV14P411C76u/?spm_id_from=333.999.0.0">B站</a></td>
</tr>
<tr>
  <td>07/14</td>
  <td><a href="https://jianhaoma.github.io/">马鉴昊</a><br>(UMich)</td>
  <td>Robust Sparse Mean Estimation</td>
  <td>[<a href="https://arxiv.org/abs/2305.15276">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1j94y1i75K/?spm_id_from=333.999.0.0">B站</a></td>
</tr>
<tr>
  <td>07/21</td>
  <td><a href="https://scholar.google.com/citations?user=xQqZt2AAAAAJ&hl=en&oi=ao">金及凯</a><br>(北京大学)</td>
  <td>Minimax optimal operator learning</td>
  <td>[<a href="https://openreview.net/pdf?id=zEn1BhaNYsC">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV15j411R781/?spm_id_from=333.999.0.0">B站</a></td>
</tr>
<tr>
  <td>07/28</td>
  <td>ICML break</td>
</tr>
<tr>
  <td>08/04</td>
  <td><a href="https://bhwangfy.github.io/">王博涵</a><br>(中国科学<br>技术大学)</td>
  <td>When and Why Momentum Accelerates SGD</td>
  <td>[<a href="https://arxiv.org/abs/2306.09000">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1UX4y177Nj/?spm_id_from=333.999.0.0">B站</a></td>
</tr>
<tr>
  <td>08/11</td>
  <td><a href="http://www.tengjiaye.com">滕佳烨</a><br>(清华大学)</td>
  <td>Predictive inference with feature conformal prediction</td>
  <td>[<a href="https://arxiv.org/abs/2210.00173">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1wu411H7uS/?spm_id_from=444.41.list.card_archive.click&vd_source=b4876af8d074c6098e2e57b5327d37ca">B站</a></td>
</tr>
<tr>
  <td>08/18</td>
  <td><a href="http://www.tengjiaye.com">蔡天乐</a><br>(Princeton)</td>
  <td>Large Language Models as Tool Makers</td>
  <td>[<a href="https://arxiv.org/abs/2305.17126">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1Bm4y1H7Pc/?spm_id_from=333.999.0.0">B站</a></td>
</tr>
</table>

<br> 2023 R01 </br>
<table>
<tr>
  <td>Time</td>
  <td>Speaker</td>
  <td>Talk Title</td>
  <td>Paper</td>
  <td>Video</td>
</tr>
<tr>
  <td> (Special) 05/26</td>
  <td><a href="https://sites.google.com/view/jingzhao/home">张景昭</a><br>(清华大学)</td>
  <td>Two Phases of Scaling Laws for Nearest Neighbor Classifiers</td>
  <td>[<a href="https://arxiv.org/pdf/2308.08247.pdf">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1ez4y1B7F1">B站</a></td>
</tr>
<tr>
  <td>03/03</td>
  <td><a href="https://zdhnarsil.github.io/">张鼎怀</a><br>(Mila)</td>
  <td>GFlowNets: Exploration for Probabilistic Inference</td>
  <td>[<a href="https://arxiv.org/abs/2210.00999">1</a>],[<a href="https://arxiv.org/abs/2202.01361">2</a>],[<a href="https://arxiv.org/abs/2110.03372">3</a>],[<a href="https://arxiv.org/abs/2209.02606">4</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1WL41117Sx">B站</a></td>
</tr>
<tr>
  <td>03/10</td>
  <td><a href="https://scholar.google.com/citations?user=6iYQL8MAAAAJ&hl=zh-CN&oi=ao">顾欣然</a><br>(清华大学)</td>
  <td>Why (and When) does Local SGD Generalize Better than SGD</td>
  <td>[<a href="https://openreview.net/forum?id=svCcui6Drl">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1iX4y1S7Kz">B站</a></td>
</tr>
<tr>
  <td>03/17</td>
  <td><a href="https://bhwangfy.github.io/">王博涵</a><br>(中国科学<br>技术大学)</td>
  <td>Provable Benefit of Adaptivity in ADAM</td>
  <td>[<a href="https://arxiv.org/abs/2208.09900">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV19L411k7gP">B站</a></td>
</tr>
<tr>
  <td>03/24</td>
  <td><a href="https://whenwen.github.io/">温凯越</a><br>(清华大学)</td>
  <td>How Does Sharpness-Aware Minimization Minimize Sharpness?</td>
  <td>[<a href="https://arxiv.org/abs/2211.05729">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1i84y1u7BJ">B站</a></td>
</tr>
<tr>
  <td>03/31</td>
  <td><a href="https://zbh2047.github.io/">张博航</a><br>(北京大学)</td>
  <td>Rethinking the Expressive Power of GNNs via Graph Biconnectivity</td>
  <td>[<a href="https://openreview.net/forum?id=r9hNv76KoT3">1</a>] (ICLR 2023 Outstanding Paper)</td>
  <td><a href="https://www.bilibili.com/video/BV1WN411N7JY">B站</a></td>
</tr>
<tr>
  <td>04/07</td>
  <td><a href="https://jianhaoma.github.io/">马鉴昊</a>(UMich)</td>
  <td>Escaping Saddle Points Or Not?</td>
  <td>[<a href="https://arxiv.org/abs/2302.10963">1</a>], [<a href="https://arxiv.org/abs/2202.08788">2</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1qc411W7Jq">B站</a></td>
</tr>
<tr>
  <td>04/14</td>
  <td><a href="https://truenobility303.github.io/">陈乐偲</a><br>(复旦大学)</td>
  <td>On Bilevel Optimization without Lower-level Strong Convexity</td>
  <td>[<a href="https://arxiv.org/abs/2301.00712">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1mh4y1p7tm">B站</a></td>
</tr>
<tr>
  <td>04/21</td>
  <td><a href="https://hackyhuang.github.io/">黄凯旋</a>(Princeton)</td>
  <td>Score Approximation, Estimation and Distribution Recovery of Diffusion Models on Low-Dimensional Data</td>
  <td>[<a href="https://arxiv.org/abs/2302.07194">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1Pc411J75N">B站</a></td>
</tr>
<tr>
  <td>04/28</td>
  <td><a href="https://diamond-duke.github.io/">戴言</a><br>(清华大学)</td>
  <td>Variance-Aware Sparse Linear Bandits</td>
  <td>[<a href="https://openreview.net/forum?id=tkwP32nsEq">1</a>]</td>
  <td><a href="https://www.bilibili.com/video/BV1sg4y1L7LW">B站</a></td>
</tr>
</table>

<div id="footer">
<div id="footer-text">
Page generated 2021-05-14 16:25:26 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
